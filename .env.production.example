# ================================================
# ðŸš€ PRODUCTION PROFILE (40GB VRAM - L40S, A100, etc.)
# ================================================
# Copy this file to .env and adjust as needed
# Usage: HARDWARE_PROFILE=production or let auto-detect

HARDWARE_PROFILE=production

# ================================================
# Hardware Configuration
# ================================================
MAX_VRAM_GB=38.0
DEVICE=cuda
TORCH_DTYPE=bfloat16

# ================================================
# Model Settings - Optimized for 40GB VRAM
# ================================================

# Whisper ASR (~6GB with float16, batch processing)
WHISPER_MODEL=large-v3
WHISPER_DEVICE=cuda
WHISPER_COMPUTE_TYPE=float16
WHISPER_BATCH_SIZE=16

# Qwen2-VL Vision Model (~4GB with flash attention)
QWEN_MODEL_PATH=models/qwen2-vl-2b
QWEN_MAX_PIXELS=604800
QWEN_MIN_PIXELS=50176
QWEN_BATCH_SIZE=8
QWEN_USE_FLASH_ATTENTION=true
QWEN_COMPILE=true

# LLM Configuration
# Option 1: Ollama with larger model (~10GB)
OLLAMA_URL=http://localhost:11434
OLLAMA_MODEL=qwen2.5:14b-instruct-q4_K_M
LLAMA_MAX_LENGTH=8192
LLAMA_TEMPERATURE=0.7

# Option 2: vLLM (faster inference, ~12GB)
# Uncomment to use vLLM instead of Ollama
# USE_VLLM=true
# VLLM_MODEL=Qwen/Qwen2.5-14B-Instruct
# VLLM_TENSOR_PARALLEL_SIZE=1
# VLLM_GPU_MEMORY_UTILIZATION=0.3
# VLLM_MAX_MODEL_LEN=8192
# VLLM_DTYPE=float16

# ================================================
# Processing Settings - Aggressive Performance
# ================================================
PRELOAD_ALL_MODELS=true
MODELS_STAY_IN_MEMORY=true
USE_TORCH_COMPILE=true

# Frame processing
FRAME_EXTRACTION_FPS=0.2
MAX_FRAMES_PER_VIDEO=200
FRAME_BATCH_SIZE=8

# Quiz generation
QUIZ_BATCH_SIZE=5

# Video limits (higher for production)
MAX_VIDEO_SIZE_MB=1000
MAX_VIDEO_DURATION_MINUTES=120
MIN_SEGMENT_DURATION=30
MAX_SEGMENT_DURATION=300

# Quiz settings
QUIZZES_PER_SEGMENT=3
QUIZ_OPTIONS_COUNT=4

# ================================================
# Database
# ================================================
DATABASE_URL=postgresql+asyncpg://postgres:postgres@localhost:5432/vier
DATABASE_ECHO=false

# ================================================
# Redis
# ================================================
REDIS_URL=redis://localhost:6379/0
REDIS_CACHE_TTL=3600

# ================================================
# S3/MinIO Storage
# ================================================
S3_ENABLED=true
S3_ENDPOINT=http://localhost:9000
S3_ACCESS_KEY=minioadmin
S3_SECRET_KEY=minioadmin
S3_BUCKET=vier-videos
S3_REGION=us-east-1
S3_USE_SSL=false
S3_SIGNED_URL_EXPIRY=3600

# Optional: Use external S3/CDN for production
# S3_ENDPOINT=https://s3.amazonaws.com
# S3_PUBLIC_URL=https://cdn.yourdomain.com
# S3_USE_SSL=true

# ================================================
# API Settings
# ================================================
API_V1_PREFIX=/api
PROJECT_NAME=AI Video Quiz Generator
DEBUG=false
HOST=0.0.0.0
PORT=8000

# Task management
TASK_TIMEOUT_SECONDS=7200
CLEANUP_TEMP_FILES_AFTER_SECONDS=86400

# YouTube download
YT_DLP_FORMAT=bestvideo[ext=mp4]+bestaudio[ext=m4a]/best[ext=mp4]/best
YT_DLP_MAX_FILESIZE=1000M
